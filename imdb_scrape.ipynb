{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape IMDB data\n",
    "**Author:** David S. White <br /> \n",
    "**Email:** dswhite2012@gmail.com <br /> \n",
    "**Date:** 2020-05-04 <br /> \n",
    "\n",
    "### Goal\n",
    "The goal of this notebook is to scrape data from IMDB within a specified range of years. This data will be used to build a model to predict IMDB user ratings. \n",
    "\n",
    "This code was developed with great help from a DataQuest turorial: https://www.dataquest.io/blog/web-scraping-beautifulsoup/. Modifications to that code include:\n",
    "* grab more variables, such as rating, genre, and run time\n",
    "* iterate over multiple years \n",
    "* for each year, scrape a user-specified number of pages\n",
    "\n",
    "The data is saved using the user provide file name as a .csv.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 1970   # first year\n",
    "end_year = 2019     # last year you want data for\n",
    "pages_per_year = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'data/imdb-data_' + str(start_year) + '-'+ str(end_year)\n",
    "file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping Function using Beautiful Soup \n",
    "Note: this function is modifed from code obtained at https://www.dataquest.io/blog/web-scraping-beautifulsoup/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_year(str_value):\n",
    "    # note, money will still contain currency symbol (e.g. $, EUR, ...) and will need to be removed.\n",
    "    str_value = str_value.replace(' ','')\n",
    "    if str_value[0] == '(':\n",
    "        x = len(str_value)\n",
    "        str_value = int(str_value[x-5:x-1])\n",
    "\n",
    "    return str_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _grab_from_page(url): \n",
    "    response = get(url)\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # movie containers (manually identified prior to function)\n",
    "    movie_containers = html_soup.find_all('div', class_ = 'lister-item mode-advanced')\n",
    "    \n",
    "    # grab data \n",
    "    names = []\n",
    "    years = []\n",
    "    ratings = []\n",
    "    run_times = []\n",
    "    genres = []\n",
    "    imdb_ratings = []\n",
    "    metascores = []\n",
    "    votes = []\n",
    "    \n",
    "    # Extract data from individual movie container\n",
    "    for container in movie_containers:\n",
    "    # Extract movies with metascore (only movies have metascores)\n",
    "        if container.find('div', class_ = 'ratings-metascore') is not None:\n",
    "        \n",
    "        # Name\n",
    "            name = container.h3.a.text\n",
    "            names.append(name)\n",
    "        \n",
    "        # Year\n",
    "            year = _clean_year(container.h3.find('span', class_ = 'lister-item-year').text)\n",
    "            years.append(year)\n",
    "\n",
    "        # Rating\n",
    "            if container.p.find('span', class_ = 'certificate') is not None:\n",
    "                rating = container.p.find('span', class_ = 'certificate').text\n",
    "            else: \n",
    "                rating = \"Unrated\"\n",
    "            ratings.append(rating)\n",
    "        \n",
    "        # Run Time (convert to int)\n",
    "            run_time = container.p.find('span', class_ = 'runtime').text\n",
    "            run_times.append(int(run_time[0:-4]))\n",
    "        \n",
    "        # Genre (returns up to 3 genres per movie)\n",
    "            genre = container.p.find('span', class_ = 'genre').text\n",
    "            # requires cleaing up to remove extra line and white space. \n",
    "            genre = genre[1:]\n",
    "            genre = genre.replace(\" \",\"\")\n",
    "            genre = genre.split(\",\")\n",
    "            genres.append(genre)\n",
    "        \n",
    "        # IMDB rating\n",
    "            imdb = float(container.strong.text)\n",
    "            imdb_ratings.append(imdb)\n",
    "        \n",
    "        # Metascore\n",
    "            m_score = container.find('span', class_ = 'metascore').text\n",
    "            metascores.append(int(m_score))\n",
    "        \n",
    "        # The number of votes\n",
    "            vote = container.find('span', attrs = {'name':'nv'})['data-value']\n",
    "            votes.append(int(vote))\n",
    "\n",
    "    # Make into data frame\n",
    "    page_df = pd.DataFrame({'movie': names,\n",
    "        'year': years,\n",
    "        'rating': ratings,\n",
    "        'runtime': run_times,\n",
    "        'genre': genres,\n",
    "        'imdbscore': imdb_ratings,\n",
    "        'metascore': metascores,\n",
    "        'votes': votes})\n",
    "    \n",
    "    return page_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Web Scraping\n",
    "Note: this may take a few minutes to run depending on the number of years and pages per year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(start_year, end_year+1)\n",
    "counts = (np.arange(0, pages_per_year) * 50) + 1    # 50 movies per page, url modified by number of movies\n",
    "for year in years:\n",
    "    print(\"Year:\", year)\n",
    "    for count in counts:\n",
    "        if year == years[0]:\n",
    "            url = \"https://www.imdb.com/search/title/?year=\"+str(year)+\"&title_type=feature&\"\n",
    "        else:\n",
    "            url = \"https://www.imdb.com/search/title/?title_type=feature&year=\"+str(year)+\"-01-01,\"+str(year)+\"-12-31&start=\"+str(count)+\"&ref_=adv_nxt\"\n",
    "        if year == years[0] and count == counts[0]:\n",
    "            imdb = _grab_from_page(url)\n",
    "        else:\n",
    "            df1 = _grab_from_page(url)\n",
    "            imdb = pd.concat([imdb, df1], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb.to_csv(file_name+\".csv\", index = False)\n",
    "print(file_name+\".csv Saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
